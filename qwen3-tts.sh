#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Qwen3-TTS Gradio App (MPS Optimized | Single File | Fixed)
âœ… ä¿®å¤: æŒ‰é’®é‡å¤ç»‘å®šå¯¼è‡´åŒé‡ç”Ÿæˆ
âœ… ä¿®å¤: voice/ref_audio å‚æ•°å†²çª
âœ… ä¿®å¤: Language ç¡¬ç¼–ç ä¸º en
âœ… ä¿®å¤: mx.metal.clear_cache å¼ƒç”¨è­¦å‘Š
âœ… ä¿®å¤: Gradio theme å‚æ•°ä½ç½®è­¦å‘Š
âœ… ä¼˜åŒ–: ä¸­æ–‡æ–‡æœ¬è‡ªåŠ¨æ£€æµ‹è¯­è¨€
"""

import os
import sys
import gc
import random
import shutil
import tempfile
import time
import warnings
from datetime import datetime
from huggingface_hub import snapshot_download #æ£€æµ‹æ¨¡å‹ä¸å­˜åœ¨æ—¶è‡ªåŠ¨ä¸‹è½½
import scipy.io.wavfile as wavfile # ç”¨äºä¿å­˜éŸ³é¢‘

# === 1. ç¯å¢ƒé…ç½® (MPS ä¼˜åŒ– + è­¦å‘ŠæŠ‘åˆ¶) ===
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["GRADIO_ANALYTICS_ENABLED"] = "false"
os.environ["FIX_MISTRAL_REGEX"] = "1"  # ğŸ”§ ä¿®å¤ tokenizer æ­£åˆ™è­¦å‘Š

# æŠ‘åˆ¶å·²çŸ¥æ— å®³è­¦å‘Š
warnings.filterwarnings("ignore", message=".*FP16 is not supported on CPU.*")
warnings.filterwarnings("ignore", message=".*model of type qwen3_tts.*")

import gradio as gr
import mlx.core as mx
import numpy as np

# å…³é”®å¯¼å…¥
try:
    from mlx_audio.tts.utils import load_model
    from mlx_audio.tts.generate import generate_audio
    import mlx_whisper
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}\nè¯·è¿è¡Œ: pip install -r requirements.txt")
    sys.exit(1)

# === 2. å…¨å±€é…ç½® ===
PROJECT_ROOT = os.getcwd()
MODELS_DIR = os.path.join(PROJECT_ROOT, "models")
os.makedirs(MODELS_DIR, exist_ok=True)

# æ¨¡å‹æ˜ å°„ 
MODEL_MAP = {
    "Pro-Custom": "Qwen3-TTS-12Hz-1.7B-CustomVoice-8bit",
    "Pro-Design": "Qwen3-TTS-12Hz-1.7B-VoiceDesign-8bit", 
    "Pro-Clone": "Qwen3-TTS-12Hz-1.7B-Base-8bit",
}

# --- 1. UI åˆ†ç±»é…ç½® (ç”¨äºç•Œé¢æ˜¾ç¤º) ---
SPEAKER_MAP = {
    "English": ["Ryanç”œèŒ¶(å¹´è½»ç”·å£°)", "Aidenè‰¾ç™»(è‡ªç„¶ç”·å£°)", "Serenaè‹ç‘¶(æ¸©æŸ”å¥³å£°)", "Vivianåä¸‰(æ´»æ³¼å¥³å£°)"],
    "Chinese": ["Vivianåä¸‰(æ´»æ³¼å¥³å£°)", "Serenaè‹ç‘¶(æ¸©æŸ”å¥³å£°)", "Uncle_Fuç¦ä¼¯(æˆç†Ÿç”·å£°)", "Dylanæ™“ä¸œ(åŒ—äº¬è¯)", "Ericç¨‹å·(å››å·è¯)"],
    "Japanese": ["Ono_Annaå°é‡æ(å…ƒæ°”å¥³å£°)"],
    "Korean": ["Soheeç´ ç†™(ç”œç¾å¥³å£°)"],
}

# --- 2. åç«¯ ID æ˜ å°„è¡¨ (ç”¨äºé€»è¾‘è½¬æ¢) ---
SPEAKER_ID_MAP = {
    "Ryanç”œèŒ¶(å¹´è½»ç”·å£°)": "ryan",
    "Aidenè‰¾ç™»(è‡ªç„¶ç”·å£°)": "aiden",
    "Vivianåä¸‰(æ´»æ³¼å¥³å£°)": "vivian",
    "Serenaè‹ç‘¶(æ¸©æŸ”å¥³å£°)": "serena",
    "Uncle_Fuç¦ä¼¯(æˆç†Ÿç”·å£°)": "uncle_fu",
    "Dylanæ™“ä¸œ(åŒ—äº¬è¯)": "dylan",
    "Ericç¨‹å·(å››å·è¯)": "eric",
    "Ono_Annaå°é‡æ(å…ƒæ°”å¥³å£°)": "ono_anna",
    "Soheeç´ ç†™(ç”œç¾å¥³å£°)": "sohee"
}
# ==== æƒ…æ„Ÿåˆ†ç±»é…ç½® (ç”¨äºç•Œé¢æ˜¾ç¤º) ========
EMOTION_MAP = {
    "å¹³é™ (Normal)": "Normal tone",
    "æ‚²ä¼¤ (Sad)": "Sad",
    "å…´å¥‹ (Excited)": "Excited",
    "æ„¤æ€’ (Angry)": "Angry",
    "ç»†è¯­ (Whispering)": "Whispering"
}
# æå– UI æ˜¾ç¤ºç”¨çš„åˆ—è¡¨
EMOTIONS = list(EMOTION_MAP.keys())
LANGUAGE_CHOICES = list(SPEAKER_MAP.keys())

# === 3. å…¨å±€çŠ¶æ€ ===
_model_cache = {}
_current_mode = "Pro-Custom"

# === 4. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ===

def _clear_mps_cache():
    """MPS ä¸“ç”¨å†…å­˜æ¸…ç† - é€‚é…æ–°ç‰ˆ mlx"""
    try:
        if mx.metal.is_available():
            # ğŸ”§ æ–°ç‰ˆ mlx ä½¿ç”¨ mx.clear_cache()
            if hasattr(mx, 'clear_cache'):
                mx.clear_cache()
            elif hasattr(mx.metal, 'clear_cache'):
                mx.metal.clear_cache()  # å…¼å®¹æ—§ç‰ˆ
    except:
        pass
    gc.collect()

def _detect_language(text: str) -> str:
    """è‡ªåŠ¨æ£€æµ‹æ–‡æœ¬è¯­è¨€ (zh/en)"""
    if not text:
        return "en"
    zh_count = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    # ä¸­æ–‡å­—ç¬¦å æ¯” >30% åˆ™åˆ¤å®šä¸ºä¸­æ–‡
    return "zh" if zh_count / len(text) > 0.3 else "en"

def _get_model(model_key: str):
    """æ‡’åŠ è½½æ¨¡å‹"""
    global _current_mode
    
    if model_key not in MODEL_MAP:
        raise gr.Error(f"æœªçŸ¥æ¨¡å‹: {model_key}")
    
    folder_name = MODEL_MAP[model_key]
    model_path = os.path.join(MODELS_DIR, folder_name)
    
    # å…¼å®¹ snapshots ç›®å½•ç»“æ„
    if not os.path.exists(model_path):
        snapshots = os.path.join(model_path, "snapshots")
        if os.path.exists(snapshots):
            subs = [d for d in os.listdir(snapshots) if not d.startswith('.')]
            if subs:
                model_path = os.path.join(snapshots, subs[0])
            else:
                raise gr.Error(f"æ¨¡å‹ç›®å½•ä¸ºç©º: {folder_name}")
        else:
            raise gr.Error(f"æ¨¡å‹ä¸å­˜åœ¨: {folder_name}")
    
    # ç¼“å­˜å‘½ä¸­
    if model_key in _model_cache and _current_mode == model_key:
        return _model_cache[model_key]
    
    # åˆ‡æ¢æ¨¡å‹æ—¶æ¸…ç†
    if _model_cache:
        print(f"ğŸ”„ åˆ‡æ¢æ¨¡å‹: {_current_mode} â†’ {model_key}")
        _model_cache.clear()
        _clear_mps_cache()
    
    print(f"â³ åŠ è½½æ¨¡å‹: {folder_name} ...")
    start = time.time()
    
    try:
        model = load_model(model_path)
        _model_cache[model_key] = model
        _current_mode = model_key
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ ({time.time()-start:.1f}s)")
        return model
    except Exception as e:
        _clear_mps_cache()
        raise gr.Error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")

def _transcribe_audio(audio_path: str) -> str:
    """ä½¿ç”¨ mlx-whisper è¿›è¡Œè¯­éŸ³è¯†åˆ« (Apple Silicon ä¼˜åŒ–ç‰ˆ)"""
    if not audio_path:
        return ""
       
    # è®¾å®šæ¨¡å‹å­˜å‚¨æ ¹ç›®å½•
    WHISPER_MODELS_DIR = os.path.join(MODELS_DIR, "mlx_whisper")
    os.makedirs(WHISPER_MODELS_DIR, exist_ok=True)
    
    # ä½ æƒ³è¦ä½¿ç”¨çš„æ¨¡å‹ ID
    model_id = "mlx-community/whisper-base-mlx" 
    
    # æ„é€ è¯¥æ¨¡å‹çš„æœ¬åœ°ç‰¹å®šç›®å½•
    # ä¾‹å¦‚ï¼šmodels/mlx_whisper/whisper-base-mlx
    local_model_path = os.path.join(WHISPER_MODELS_DIR, model_id.split('/')[-1])

    try:
        # 1. æ£€æŸ¥å¹¶ä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šç›®å½•
        if not os.path.exists(local_model_path):
            print(f"â³ æ­£åœ¨ä¸‹è½½ Whisper æ¨¡å‹åˆ°æœ¬åœ°ç›®å½•: {local_model_path}...")
            snapshot_download(
                repo_id=model_id,
                local_dir=local_model_path,
                local_dir_use_symlinks=False # ç¦ç”¨ç¬¦å·é“¾æ¥ï¼Œç¡®ä¿æ–‡ä»¶å®å®åœ¨åœ¨ä¸‹è½½åˆ°è¯¥ç›®å½•
            )
            print("âœ… ä¸‹è½½å®Œæˆ")

        print(f"ğŸ™ï¸ æ­£åœ¨è¯†åˆ« (ä½¿ç”¨æœ¬åœ°æ¨¡å‹): {os.path.basename(audio_path)}")
        
        # 2. è°ƒç”¨æ—¶ä¼ å…¥æœ¬åœ°è·¯å¾„è€Œé Repo ID
        result = mlx_whisper.transcribe(
            audio_path, 
            path_or_hf_repo=local_model_path 
        )
        
        _clear_mps_cache()
        return result["text"].strip()
        
    except Exception as e:
        print(f"âš ï¸ Whisper è¯†åˆ«æˆ–ä¸‹è½½å¤±è´¥: {e}")
        return "ã€è¯†åˆ«å¤±è´¥ã€‘"

def _generate_tts(text: str, speaker: str, emotion: str, speed: float, 
                  ref_audio: str, ref_text: str, seed: int, model_key: str, design_text: str = ""):
    """TTS ç”Ÿæˆä¸»é€»è¾‘ - å·²æ•´åˆå®˜æ–¹ç±»æ–¹æ³•ä¸æ€§èƒ½æ—¥å¿—"""
    
    model = None
    temp_dir = None
    
    if not text or not text.strip():
        raise gr.Error("âš ï¸ åˆæˆæ–‡æœ¬ä¸èƒ½ä¸ºç©º")
    
    try:
        # 1. åˆå§‹åŒ–è®¾ç½®
        actual_seed = int(seed) if (seed is not None and seed != -1) else random.randint(0, 2**32-1)
        mx.random.seed(actual_seed)
        random.seed(actual_seed)
        np.random.seed(actual_seed)
        
        # åŠ è½½å¯¹åº”çš„ Pro æ¨¡å‹
        model = _get_model(model_key)
        
        # å¼€å§‹è®¡æ—¶
        start_time = time.time()
        
        # ç»Ÿä¸€è¯­è¨€åç§°æ ¼å¼ (VoiceDesign å®˜æ–¹ç¤ºä¾‹è¦æ±‚å…¨ç§°)
        raw_lang = _detect_language(text)
        full_lang = "Chinese" if raw_lang == "zh" else "English"

        # 2. åˆ†æ¨¡å¼è°ƒç”¨å®˜æ–¹ç±»æ–¹æ³• (ä¸å†ä½¿ç”¨é€šç”¨çš„ generate_audio)
        results = []
        
        if model_key == "Pro-Clone":
            # === æ¨¡å¼ A: é›¶æ ·æœ¬å…‹éš† (Base æ¨¡å‹) ===
            actual_ref_text = ref_text
            if not actual_ref_text or not actual_ref_text.strip():
                actual_ref_text = _transcribe_audio(ref_audio)
            
            print(f"ğŸ§¬ æ‰§è¡Œå…‹éš†ç”Ÿæˆ (Seed: {actual_seed})...")
            results = list(model.generate(
                text=text.strip(),
                ref_audio=ref_audio,
                ref_text=actual_ref_text,
                language=full_lang
            ))

        elif model_key == "Pro-Design":
            # === æ¨¡å¼ B: è¯­éŸ³è®¾è®¡ (VoiceDesign æ¨¡å‹) ===
            print(f"ğŸ¨ æ‰§è¡Œè¯­éŸ³è®¾è®¡ç”Ÿæˆ (Seed: {actual_seed})...")
            # ğŸ”§ ä¿®å¤: ç§»é™¤ä¸æ”¯æŒçš„ speed å‚æ•°
            results = list(model.generate_voice_design(
                text=text.strip(),
                language=full_lang,
                instruct=design_text or "A natural clear voice."
            ))

        else:
            # === æ¨¡å¼ C: å®˜æ–¹è§’è‰² (CustomVoice æ¨¡å‹) ===
            print(f"ğŸ‘¤ æ‰§è¡Œè§’è‰²å®šåˆ¶ç”Ÿæˆ (Seed: {actual_seed})...")
            
            # ğŸ”§ å…³é”®ä¿®å¤ï¼šå°† UI ä¸Šçš„ä¸­æ–‡æè¿°è½¬æ¢ä¸ºæ¨¡å‹èƒ½è¯†åˆ«çš„è‹±æ–‡ ID
            # é€»è¾‘ï¼šå…ˆå»è¡¨é‡ŒæŸ¥ï¼ŒæŸ¥ä¸åˆ°åˆ™è½¬å°å†™å°è¯•ï¼Œæœ€åé»˜è®¤å›è½ vivian
            speaker_id = SPEAKER_ID_MAP.get(speaker, speaker.lower() if speaker else "vivian")
            
            print(f"   [æ˜ å°„è½¬æ¢]: {speaker} -> {speaker_id}")
            
            results = list(model.generate_custom_voice(
                text=text.strip(),
                speaker=speaker_id,  # ğŸ‘ˆ è¿™é‡Œå¿…é¡»ä¼ è½¬æ¢åçš„è‹±æ–‡ ID
                language=full_lang,
                instruct=emotion
            ))

        # 3. å¤„ç†ç”Ÿæˆç»“æœ
        if not results or not hasattr(results[0], 'audio'):
            raise Exception("æ¨¡å‹æœªè¿”å›æœ‰æ•ˆçš„éŸ³é¢‘æ•°æ®")

        # ç»“æŸè®¡æ—¶
        end_time = time.time()
        elapsed = end_time - start_time
        
        # æå–éŸ³é¢‘æ•°æ®
        audio_data = np.array(results[0].audio)
        duration = len(audio_data) / 24000 # Qwen3 é»˜è®¤ä¸º 24k é‡‡æ ·ç‡
        
        # 4. æ‰“å°æ€§èƒ½æ—¥å¿—ä¸ä¿®å¤å¼ƒç”¨è­¦å‘Š
        print("\n" + "="*20)
        print(f"Duration:          {duration:.2f}s")
        print(f"Processing Time:   {elapsed:.2f}s")
        print(f"Real-time Factor:  {duration/elapsed:.2f}x")
        
        # ğŸ”§ ä¿®å¤å¼ƒç”¨è­¦å‘Š: ä¼˜å…ˆä½¿ç”¨æ–° API
        try:
            peak_mem = mx.get_peak_memory() / 1024**3
        except AttributeError:
            peak_mem = mx.metal.get_peak_memory() / 1024**3
            
        print(f"Peak Memory:       {peak_mem:.2f}GB")
        print("="*20 + "\n")

        # 5. ä¿å­˜éŸ³é¢‘æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        final_path = os.path.join(tempfile.gettempdir(), f"qwen3_output_{int(time.time())}.wav")
        wavfile.write(final_path, 24000, audio_data)
        
        return final_path, actual_seed

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise gr.Error(f"åˆæˆå¤±è´¥: {str(e)}")
    finally:
        # æ¸…ç†å†…å­˜
        _clear_mps_cache()

# === 5. Gradio UI æ„å»º ===

def update_speakers(lang: str):
    """è¯­è¨€åˆ‡æ¢è”åŠ¨"""
    speakers = SPEAKER_MAP.get(lang, [])
    return gr.update(choices=speakers, value=speakers[0] if speakers else None)

def switch_mode(mode_label: str):
    """æ¨¡å¼åˆ‡æ¢ + æ›´æ–°å…¨å±€æ¨¡å‹ Key"""
    global _current_mode
    mapping = {
        "å®˜æ–¹è§’è‰²": "Pro-Custom",
        "è¯­éŸ³è®¾è®¡": "Pro-Design", 
        "é›¶æ ·æœ¬å…‹éš†": "Pro-Clone"
    }
    _current_mode = mapping.get(mode_label, "Pro-Custom")
    
    return [
        gr.update(visible=(mode_label == "å®˜æ–¹è§’è‰²")),
        gr.update(visible=(mode_label == "è¯­éŸ³è®¾è®¡")),
        gr.update(visible=(mode_label == "é›¶æ ·æœ¬å…‹éš†"))
    ]

# ğŸ”§ ä¿®å¤: theme å‚æ•°ç§»åˆ° launch() æ–¹æ³•
with gr.Blocks(title="Qwen3-TTS Pro") as demo:
    gr.Markdown("## ğŸ™ï¸ Qwen3 Neural Voice Engine (MPS Optimized)")
    
    with gr.Row():
        # === å·¦ä¾§æ§åˆ¶é¢æ¿ ===
        with gr.Column(scale=1):
            mode_nav = gr.Radio(
                ["å®˜æ–¹è§’è‰²", "è¯­éŸ³è®¾è®¡", "é›¶æ ·æœ¬å…‹éš†"], 
                label="ğŸ”§ åŠŸèƒ½æ¨¡å¼", 
                value="å®˜æ–¹è§’è‰²"
            )
            seed_input = gr.Number(value=-1, label="ğŸ² éšæœºç§å­ (-1=éšæœº)", precision=0)
            
            # æ¨¡å¼ 1: å®˜æ–¹è§’è‰²
            with gr.Group(visible=True) as group_custom:
                gr.Markdown("### ğŸ‘¤ è§’è‰²è®¾ç½®")
                lang_sel = gr.Dropdown(LANGUAGE_CHOICES, value="Chinese", label="è¯­è¨€")
                spk_sel = gr.Dropdown(SPEAKER_MAP["Chinese"], value="Vivianåä¸‰(æ´»æ³¼å¥³å£°)", label="è§’è‰²")
                emo_sel = gr.Dropdown(EMOTIONS, value="å¹³é™ (Normal)", label="æƒ…æ„Ÿ")
                speed_sel = gr.Slider(0.5, 2.0, value=1.0, step=0.1, label="è¯­é€Ÿ")
            
            # æ¨¡å¼ 2: è¯­éŸ³è®¾è®¡
            with gr.Group(visible=False) as group_design:
                gr.Markdown("### ğŸ¨ å£°éŸ³æè¿°")
                design_input = gr.Textbox(
                    label="æè¿°æç¤ºè¯", 
                    placeholder="ä¾‹: ç£æ€§ç”·å£°ï¼Œç•¥å¸¦æ²™å“‘ï¼Œè¯­é€Ÿç¼“æ…¢",
                    lines=2
                )
            
            # æ¨¡å¼ 3: é›¶æ ·æœ¬å…‹éš†
            with gr.Group(visible=False) as group_clone:
                gr.Markdown("### ğŸ§¬ å‚è€ƒéŸ³é¢‘")
                ref_aud = gr.Audio(label="ä¸Šä¼ å‚è€ƒéŸ³é¢‘ (â‰¤30s)", type="filepath")
                ref_txt = gr.Textbox(label="å‚è€ƒæ–‡æœ¬ (å¯é€‰ï¼Œç•™ç©ºè‡ªåŠ¨è¯†åˆ«)", lines=2)
                ref_aud.change(
                    fn=_transcribe_audio, 
                    inputs=ref_aud, 
                    outputs=ref_txt,
                    show_progress="minimal"
                )
        
        # === å³ä¾§è¾“å‡ºé¢æ¿ ===
        with gr.Column(scale=2):
            text_input = gr.Textbox(
                label="ğŸ“ åˆæˆæ–‡æœ¬", 
                lines=6, 
                placeholder="è¾“å…¥è¦åˆæˆçš„å†…å®¹...",
                max_lines=20
            )
            gen_btn = gr.Button("ğŸš€ å¼€å§‹ç”Ÿæˆ", variant="primary", size="lg")
            
            # ğŸ”§ ä¿®å¤: autoplay=False é¿å…åŒé‡æ’­æ”¾
            out_aud = gr.Audio(label="ğŸ”Š è¾“å‡ºç»“æœ", interactive=False, autoplay=True)
            res_seed = gr.Number(label="å®é™…ä½¿ç”¨ç§å­", interactive=False)
            
            gr.HTML("""
                <div style="text-align:center;margin-top:20px;color:#666;font-size:12px">
                    MPS Accelerated | Auto Memory Cleanup | 
                    <a href="https://github.com/Rayen21/qwen3-TTS-Mac" target="_blank">GitHub</a>
                </div>
            """)
    
    # === äº‹ä»¶ç»‘å®š ===
    lang_sel.change(fn=update_speakers, inputs=lang_sel, outputs=spk_sel)
    mode_nav.change(
        fn=switch_mode, 
        inputs=mode_nav, 
        outputs=[group_custom, group_design, group_clone]
    )
    
    # ğŸ”§ ç¡®ä¿ inputs åˆ—è¡¨ä¸­åŒ…å«äº† design_input (å¯¹åº” UI ä¸Šçš„æ–‡æœ¬æ¡†)
    gen_btn.click(
        fn=lambda t, spk, emo, spd, ra, rt, sd, dt: _generate_tts(
            t, spk, emo, spd, ra, rt, sd, _current_mode, dt
        ),
        inputs=[text_input, spk_sel, emo_sel, speed_sel, ref_aud, ref_txt, seed_input, design_input],
        outputs=[out_aud, res_seed],
        show_progress="full"
    )

# === 6. å¯åŠ¨å…¥å£ ===
if __name__ == "__main__":
    print("ğŸ”§ Qwen3-TTS Pro å¯åŠ¨ä¸­ (MPS ä¼˜åŒ–ç‰ˆ | Fixed)...")
    print(f"ğŸ“ æ¨¡å‹ç›®å½•: {MODELS_DIR}")
    print(f"ğŸ–¥ï¸  MPS å¯ç”¨: {mx.metal.is_available()}")
    
    try:
        # ğŸ”§ ä¿®å¤: theme å‚æ•°ç§»åˆ° launch() æ–¹æ³•
        demo.launch(
            server_port=9860,
            inbrowser=True,
            quiet=False,
            theme=gr.themes.Soft()
        )
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ­£åœ¨æ¸…ç†å†…å­˜...")
        _clear_mps_cache()
        print("âœ… é€€å‡ºå®Œæˆ")
