#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Qwen3-TTS Gradio App (MPS Optimized | Single File | Fixed)
âœ… ä¿®å¤: æŒ‰é’®é‡å¤ç»‘å®šå¯¼è‡´åŒé‡ç”Ÿæˆ
âœ… ä¿®å¤: voice/ref_audio å‚æ•°å†²çª
âœ… ä¿®å¤: Language ç¡¬ç¼–ç ä¸º en
âœ… ä¿®å¤: mx.metal.clear_cache å¼ƒç”¨è­¦å‘Š
âœ… ä¿®å¤: Gradio theme å‚æ•°ä½ç½®è­¦å‘Š
âœ… ä¼˜åŒ–: ä¸­æ–‡æ–‡æœ¬è‡ªåŠ¨æ£€æµ‹è¯­è¨€
"""

import os
import sys
import gc
import random
import shutil
import tempfile
import time
import warnings
from datetime import datetime
from huggingface_hub import snapshot_download #æ£€æµ‹æ¨¡å‹ä¸å­˜åœ¨æ—¶è‡ªåŠ¨ä¸‹è½½

# === 1. ç¯å¢ƒé…ç½® (MPS ä¼˜åŒ– + è­¦å‘ŠæŠ‘åˆ¶) ===
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["GRADIO_ANALYTICS_ENABLED"] = "false"
os.environ["FIX_MISTRAL_REGEX"] = "1"  # ğŸ”§ ä¿®å¤ tokenizer æ­£åˆ™è­¦å‘Š

# æŠ‘åˆ¶å·²çŸ¥æ— å®³è­¦å‘Š
warnings.filterwarnings("ignore", message=".*FP16 is not supported on CPU.*")
warnings.filterwarnings("ignore", message=".*model of type qwen3_tts.*")

import gradio as gr
import mlx.core as mx
import numpy as np

# å…³é”®å¯¼å…¥
try:
    from mlx_audio.tts.utils import load_model
    from mlx_audio.tts.generate import generate_audio
    import mlx_whisper
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}\nè¯·è¿è¡Œ: pip install -r requirements.txt")
    sys.exit(1)

# === 2. å…¨å±€é…ç½® ===
PROJECT_ROOT = os.getcwd()
MODELS_DIR = os.path.join(PROJECT_ROOT, "models")
os.makedirs(MODELS_DIR, exist_ok=True)

# æ¨¡å‹æ˜ å°„ 
MODEL_MAP = {
    #"Pro-Custom": "Qwen3-TTS-12Hz-1.7B-CustomVoice-8bit", #å®˜æ–¹é¢„è®¾è§’è‰²
    "Pro-Custom": "Qwen3-TTS-12Hz-0.6B-CustomVoice-8bit",
    "Pro-Design": "Qwen3-TTS-12Hz-1.7B-VoiceDesign-bf16", #è¯­éŸ³è®¾è®¡
    #"Pro-Clone": "Qwen3-TTS-12Hz-1.7B-Base",              #é›¶æ ·æœ¬å…‹éš†
    "Pro-Clone": "Qwen3-TTS-12Hz-1.7B-Base-8bit",
    #"Pro-Clone": "Qwen3-TTS-12Hz-0.6B-Base-bf16",
}

# UI é…ç½®æ•°æ®
SPEAKER_MAP = {
    "English": ["Ryan", "Aiden", "Ethan", "Chelsie", "Serena", "Vivian"],
    "Chinese": ["Vivian", "Serena", "Uncle_Fu", "Dylan", "Eric"],
    "Japanese": ["Ono_Anna"],
    "Korean": ["Sohee"],
}
EMOTIONS = ["Normal tone", "Sad", "Excited", "Angry", "Whispering"]
LANGUAGE_CHOICES = list(SPEAKER_MAP.keys())

# === 3. å…¨å±€çŠ¶æ€ ===
_model_cache = {}
_current_mode = "Pro-Custom"

# === 4. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ===

def _clear_mps_cache():
    """MPS ä¸“ç”¨å†…å­˜æ¸…ç† - é€‚é…æ–°ç‰ˆ mlx"""
    try:
        if mx.metal.is_available():
            # ğŸ”§ æ–°ç‰ˆ mlx ä½¿ç”¨ mx.clear_cache()
            if hasattr(mx, 'clear_cache'):
                mx.clear_cache()
            elif hasattr(mx.metal, 'clear_cache'):
                mx.metal.clear_cache()  # å…¼å®¹æ—§ç‰ˆ
    except:
        pass
    gc.collect()

def _detect_language(text: str) -> str:
    """è‡ªåŠ¨æ£€æµ‹æ–‡æœ¬è¯­è¨€ (zh/en)"""
    if not text:
        return "en"
    zh_count = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    # ä¸­æ–‡å­—ç¬¦å æ¯” >30% åˆ™åˆ¤å®šä¸ºä¸­æ–‡
    return "zh" if zh_count / len(text) > 0.3 else "en"

def _get_model(model_key: str):
    """æ‡’åŠ è½½æ¨¡å‹"""
    global _current_mode
    
    if model_key not in MODEL_MAP:
        raise gr.Error(f"æœªçŸ¥æ¨¡å‹: {model_key}")
    
    folder_name = MODEL_MAP[model_key]
    model_path = os.path.join(MODELS_DIR, folder_name)
    
    # å…¼å®¹ snapshots ç›®å½•ç»“æ„
    if not os.path.exists(model_path):
        snapshots = os.path.join(model_path, "snapshots")
        if os.path.exists(snapshots):
            subs = [d for d in os.listdir(snapshots) if not d.startswith('.')]
            if subs:
                model_path = os.path.join(snapshots, subs[0])
            else:
                raise gr.Error(f"æ¨¡å‹ç›®å½•ä¸ºç©º: {folder_name}")
        else:
            raise gr.Error(f"æ¨¡å‹ä¸å­˜åœ¨: {folder_name}")
    
    # ç¼“å­˜å‘½ä¸­
    if model_key in _model_cache and _current_mode == model_key:
        return _model_cache[model_key]
    
    # åˆ‡æ¢æ¨¡å‹æ—¶æ¸…ç†
    if _model_cache:
        print(f"ğŸ”„ åˆ‡æ¢æ¨¡å‹: {_current_mode} â†’ {model_key}")
        _model_cache.clear()
        _clear_mps_cache()
    
    print(f"â³ åŠ è½½æ¨¡å‹: {folder_name} ...")
    start = time.time()
    
    try:
        model = load_model(model_path)
        _model_cache[model_key] = model
        _current_mode = model_key
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ ({time.time()-start:.1f}s)")
        return model
    except Exception as e:
        _clear_mps_cache()
        raise gr.Error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")

def _transcribe_audio(audio_path: str) -> str:
    """ä½¿ç”¨ mlx-whisper è¿›è¡Œè¯­éŸ³è¯†åˆ« (Apple Silicon ä¼˜åŒ–ç‰ˆ)"""
    if not audio_path:
        return ""
       
    # è®¾å®šæ¨¡å‹å­˜å‚¨æ ¹ç›®å½•
    WHISPER_MODELS_DIR = os.path.join(MODELS_DIR, "mlx_whisper")
    os.makedirs(WHISPER_MODELS_DIR, exist_ok=True)
    
    # ä½ æƒ³è¦ä½¿ç”¨çš„æ¨¡å‹ ID
    model_id = "mlx-community/whisper-base-mlx" 
    
    # æ„é€ è¯¥æ¨¡å‹çš„æœ¬åœ°ç‰¹å®šç›®å½•
    # ä¾‹å¦‚ï¼šmodels/mlx_whisper/whisper-base-mlx
    local_model_path = os.path.join(WHISPER_MODELS_DIR, model_id.split('/')[-1])

    try:
        # 1. æ£€æŸ¥å¹¶ä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šç›®å½•
        if not os.path.exists(local_model_path):
            print(f"â³ æ­£åœ¨ä¸‹è½½ Whisper æ¨¡å‹åˆ°æœ¬åœ°ç›®å½•: {local_model_path}...")
            snapshot_download(
                repo_id=model_id,
                local_dir=local_model_path,
                local_dir_use_symlinks=False # ç¦ç”¨ç¬¦å·é“¾æ¥ï¼Œç¡®ä¿æ–‡ä»¶å®å®åœ¨åœ¨ä¸‹è½½åˆ°è¯¥ç›®å½•
            )
            print("âœ… ä¸‹è½½å®Œæˆ")

        print(f"ğŸ™ï¸ æ­£åœ¨è¯†åˆ« (ä½¿ç”¨æœ¬åœ°æ¨¡å‹): {os.path.basename(audio_path)}")
        
        # 2. è°ƒç”¨æ—¶ä¼ å…¥æœ¬åœ°è·¯å¾„è€Œé Repo ID
        result = mlx_whisper.transcribe(
            audio_path, 
            path_or_hf_repo=local_model_path 
        )
        
        _clear_mps_cache()
        return result["text"].strip()
        
    except Exception as e:
        print(f"âš ï¸ Whisper è¯†åˆ«æˆ–ä¸‹è½½å¤±è´¥: {e}")
        return "ã€è¯†åˆ«å¤±è´¥ã€‘"

def _generate_tts(text: str, speaker: str, emotion: str, speed: float, 
                  ref_audio: str, ref_text: str, seed: int, model_key: str):
    """TTS ç”Ÿæˆä¸»é€»è¾‘ - å·²ä¼˜åŒ–ä»¥ç¬¦åˆ mlx-audio è§„èŒƒ"""
    if not text or not text.strip():
        raise gr.Error("âš ï¸ åˆæˆæ–‡æœ¬ä¸èƒ½ä¸ºç©º")
    
    # ç§å­å¤„ç†
    actual_seed = int(seed) if (seed is not None and seed != -1) else random.randint(0, 2**32-1)
    mx.random.seed(actual_seed)
    random.seed(actual_seed)
    np.random.seed(actual_seed)
    
    # åŠ è½½æ¨¡å‹
    model = _get_model(model_key)
    temp_dir = tempfile.mkdtemp(prefix="qwen3_tts_")
    
    try:
        is_clone_mode = "Clone" in model_key
        lang = _detect_language(text)
        
        # è§„èŒƒåŒ–å‚æ•°è°ƒç”¨
        gen_params = {
            "model": model,
            "text": text.strip(),
            "instruct": emotion,
            "speed": speed,
            "output_path": temp_dir,
            "language": lang
        }

        if is_clone_mode and ref_audio:
            # === ç¬¦åˆ mlx-audio è§„èŒƒçš„å…‹éš†è°ƒç”¨ ===
            actual_ref_text = ref_text
            if not actual_ref_text or not actual_ref_text.strip():
                print("ğŸ¤ è‡ªåŠ¨è¯†åˆ«å‚è€ƒéŸ³é¢‘...")
                actual_ref_text = _transcribe_audio(ref_audio)
            
            print(f"ğŸ§¬ å…‹éš†æ¨¡å¼: ref_audio={os.path.basename(ref_audio)}, lang={lang}")
            gen_params.update({
                "ref_audio": ref_audio,
                "ref_text": actual_ref_text,
                "voice": None  # æ˜ç¡®ç§»é™¤é¢„è®¾éŸ³è‰²
            })
        else:
            # === æ ‡å‡†è§’è‰²æ¨¡å¼è°ƒç”¨ ===
            voice_name = speaker.lower() if speaker else "vivian"
            print(f"ğŸ‘¤ è§’è‰²æ¨¡å¼: voice={voice_name}, lang={lang}")
            gen_params.update({
                "voice": voice_name,
                "ref_audio": None,
                "ref_text": None
            })
        
        # æ‰§è¡Œç”Ÿæˆ
        generate_audio(**gen_params)
        
        # å¤åˆ¶è¾“å‡ºæ–‡ä»¶
        src = os.path.join(temp_dir, "audio_000.wav")
        final_path = os.path.join(tempfile.gettempdir(), f"qwen3_pro_{int(time.time())}.wav")
        shutil.copy(src, final_path)
        return final_path, actual_seed

    except Exception as e:
        import traceback
        traceback.print_exc()
        raise gr.Error(f"Pro æ¨¡å‹åˆæˆå¤±è´¥: {e}")
    finally:
        if os.path.exists(temp_dir): shutil.rmtree(temp_dir)
        _clear_mps_cache()

# === 5. Gradio UI æ„å»º ===

def update_speakers(lang: str):
    """è¯­è¨€åˆ‡æ¢è”åŠ¨"""
    speakers = SPEAKER_MAP.get(lang, [])
    return gr.update(choices=speakers, value=speakers[0] if speakers else None)

def switch_mode(mode_label: str):
    """æ¨¡å¼åˆ‡æ¢ + æ›´æ–°å…¨å±€æ¨¡å‹ Key"""
    global _current_mode
    mapping = {
        "å®˜æ–¹è§’è‰²": "Pro-Custom",
        "è¯­éŸ³è®¾è®¡": "Pro-Design", 
        "é›¶æ ·æœ¬å…‹éš†": "Pro-Clone"
    }
    _current_mode = mapping.get(mode_label, "Pro-Custom")
    
    return [
        gr.update(visible=(mode_label == "å®˜æ–¹è§’è‰²")),
        gr.update(visible=(mode_label == "è¯­éŸ³è®¾è®¡")),
        gr.update(visible=(mode_label == "é›¶æ ·æœ¬å…‹éš†"))
    ]

# ğŸ”§ ä¿®å¤: theme å‚æ•°ç§»åˆ° launch() æ–¹æ³•
with gr.Blocks(title="Qwen3-TTS Pro") as demo:
    gr.Markdown("## ğŸ™ï¸ Qwen3 Neural Voice Engine (MPS Optimized)")
    
    with gr.Row():
        # === å·¦ä¾§æ§åˆ¶é¢æ¿ ===
        with gr.Column(scale=1):
            mode_nav = gr.Radio(
                ["å®˜æ–¹è§’è‰²", "è¯­éŸ³è®¾è®¡", "é›¶æ ·æœ¬å…‹éš†"], 
                label="ğŸ”§ åŠŸèƒ½æ¨¡å¼", 
                value="å®˜æ–¹è§’è‰²"
            )
            seed_input = gr.Number(value=-1, label="ğŸ² éšæœºç§å­ (-1=éšæœº)", precision=0)
            
            # æ¨¡å¼ 1: å®˜æ–¹è§’è‰²
            with gr.Group(visible=True) as group_custom:
                gr.Markdown("### ğŸ‘¤ è§’è‰²è®¾ç½®")
                lang_sel = gr.Dropdown(LANGUAGE_CHOICES, value="Chinese", label="è¯­è¨€")
                spk_sel = gr.Dropdown(SPEAKER_MAP["Chinese"], value="Vivian", label="è§’è‰²")
                emo_sel = gr.Dropdown(EMOTIONS, value="Normal tone", label="æƒ…æ„Ÿ")
                speed_sel = gr.Slider(0.5, 2.0, value=1.0, step=0.1, label="è¯­é€Ÿ")
            
            # æ¨¡å¼ 2: è¯­éŸ³è®¾è®¡
            with gr.Group(visible=False) as group_design:
                gr.Markdown("### ğŸ¨ å£°éŸ³æè¿°")
                design_input = gr.Textbox(
                    label="æè¿°æç¤ºè¯", 
                    placeholder="ä¾‹: ç£æ€§ç”·å£°ï¼Œç•¥å¸¦æ²™å“‘ï¼Œè¯­é€Ÿç¼“æ…¢",
                    lines=2
                )
            
            # æ¨¡å¼ 3: é›¶æ ·æœ¬å…‹éš†
            with gr.Group(visible=False) as group_clone:
                gr.Markdown("### ğŸ§¬ å‚è€ƒéŸ³é¢‘")
                ref_aud = gr.Audio(label="ä¸Šä¼ å‚è€ƒéŸ³é¢‘ (â‰¤30s)", type="filepath")
                ref_txt = gr.Textbox(label="å‚è€ƒæ–‡æœ¬ (å¯é€‰ï¼Œç•™ç©ºè‡ªåŠ¨è¯†åˆ«)", lines=2)
                ref_aud.change(
                    fn=_transcribe_audio, 
                    inputs=ref_aud, 
                    outputs=ref_txt,
                    show_progress="minimal"
                )
        
        # === å³ä¾§è¾“å‡ºé¢æ¿ ===
        with gr.Column(scale=2):
            text_input = gr.Textbox(
                label="ğŸ“ åˆæˆæ–‡æœ¬", 
                lines=6, 
                placeholder="è¾“å…¥è¦åˆæˆçš„å†…å®¹...",
                max_lines=20
            )
            gen_btn = gr.Button("ğŸš€ å¼€å§‹ç”Ÿæˆ", variant="primary", size="lg")
            
            # ğŸ”§ ä¿®å¤: autoplay=False é¿å…åŒé‡æ’­æ”¾
            out_aud = gr.Audio(label="ğŸ”Š è¾“å‡ºç»“æœ", interactive=False, autoplay=True)
            res_seed = gr.Number(label="å®é™…ä½¿ç”¨ç§å­", interactive=False)
            
            gr.HTML("""
                <div style="text-align:center;margin-top:20px;color:#666;font-size:12px">
                    MPS Accelerated | Auto Memory Cleanup | 
                    <a href="https://github.com/Rayen21/qwen3-TTS-Mac" target="_blank">GitHub</a>
                </div>
            """)
    
    # === äº‹ä»¶ç»‘å®š ===
    lang_sel.change(fn=update_speakers, inputs=lang_sel, outputs=spk_sel)
    mode_nav.change(
        fn=switch_mode, 
        inputs=mode_nav, 
        outputs=[group_custom, group_design, group_clone]
    )
    
    # ğŸ”§ å…³é”®ä¿®å¤: åªç»‘å®šä¸€æ¬¡ï¼Œä½¿ç”¨å…¨å±€ _current_mode ä¼ é€’ model_key
    gen_btn.click(
        fn=lambda t, spk, emo, spd, ra, rt, sd: _generate_tts(
            t, spk, emo, spd, ra, rt, sd, _current_mode
        ),
        inputs=[text_input, spk_sel, emo_sel, speed_sel, ref_aud, ref_txt, seed_input],
        outputs=[out_aud, res_seed],
        show_progress="full"
    )

# === 6. å¯åŠ¨å…¥å£ ===
if __name__ == "__main__":
    print("ğŸ”§ Qwen3-TTS Pro å¯åŠ¨ä¸­ (MPS ä¼˜åŒ–ç‰ˆ | Fixed)...")
    print(f"ğŸ“ æ¨¡å‹ç›®å½•: {MODELS_DIR}")
    print(f"ğŸ–¥ï¸  MPS å¯ç”¨: {mx.metal.is_available()}")
    
    try:
        # ğŸ”§ ä¿®å¤: theme å‚æ•°ç§»åˆ° launch() æ–¹æ³•
        demo.launch(
            server_port=9860,
            inbrowser=True,
            quiet=False,
            theme=gr.themes.Soft()
        )
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ­£åœ¨æ¸…ç†å†…å­˜...")
        _clear_mps_cache()
        print("âœ… é€€å‡ºå®Œæˆ")
